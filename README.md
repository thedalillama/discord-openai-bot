# README.md
# Version 2.23.0
# Discord AI Bot

A Discord bot that integrates with multiple AI providers (OpenAI, Anthropic,
DeepSeek) to provide intelligent responses and brainstorming support in
Discord channels.

## Quick Start

1. **Clone and install dependencies**:
   ```bash
   git clone <repository>
   cd discord-ai-bot
   pip install -r requirements.txt
   ```

2. **Configure environment** (create `.env` file):
   ```bash
   # Required
   DISCORD_TOKEN=your_discord_bot_token

   # Choose your AI provider
   AI_PROVIDER=deepseek
   OPENAI_COMPATIBLE_API_KEY=your_deepseek_key
   OPENAI_COMPATIBLE_BASE_URL=https://api.deepseek.com
   OPENAI_COMPATIBLE_MODEL=deepseek-chat
   ```

3. **Run the bot**:
   ```bash
   python main.py
   ```

---

## AI Providers

### DeepSeek (Recommended â€” Cost-Effective)
```bash
AI_PROVIDER=deepseek
OPENAI_COMPATIBLE_API_KEY=your_deepseek_key
OPENAI_COMPATIBLE_BASE_URL=https://api.deepseek.com
OPENAI_COMPATIBLE_MODEL=deepseek-chat        # Fast, cost-effective
# OPENAI_COMPATIBLE_MODEL=deepseek-reasoner  # Reasoning model with CoT display
```

**DeepSeek models:**
- `deepseek-chat` â€” General purpose, fast responses, lowest cost
- `deepseek-reasoner` â€” Chain-of-thought reasoning model; use with
  `!thinking on` to display full reasoning process in Discord

### OpenAI (GPT Models + Image Generation)
```bash
AI_PROVIDER=openai
OPENAI_API_KEY=your_openai_key
OPENAI_MODEL=gpt-4o-mini
ENABLE_IMAGE_GENERATION=true
```

### Anthropic (Claude Models)
```bash
AI_PROVIDER=anthropic
ANTHROPIC_API_KEY=your_anthropic_key
ANTHROPIC_MODEL=claude-haiku-4-5-20251001
```

### Other OpenAI-Compatible Providers
```bash
# OpenRouter
OPENAI_COMPATIBLE_BASE_URL=https://openrouter.ai/api/v1

# Local APIs (Ollama, LM Studio, etc.)
OPENAI_COMPATIBLE_BASE_URL=http://localhost:8000
```

### Provider Specifications (verified 2025-02-26)
| Provider | Model | Context Window | Max Output | Cost per 1M tokens |
|----------|-------|---------------|------------|---------------------|
| OpenAI | gpt-4o-mini | 128K | 16,384 | ~$0.15 input / $0.60 output |
| DeepSeek | deepseek-chat | 64K | 8,000 | ~$0.27 input / $1.10 output |
| DeepSeek | deepseek-reasoner | 64K | 8,000 (+32K CoT) | ~$0.55 input / $2.19 output |
| Anthropic | claude-haiku-4-5 | 200K | 64,000 | ~$0.80 input / $4.00 output |

*Prices approximate â€” check provider docs for current rates.*

---

## Context Management

The bot uses a two-layer context management system to ensure every API call
fits within the provider's context window:

1. **Message-count trim** (`MAX_HISTORY`, default 10) â€” bounds in-memory
   storage after every message append
2. **Token-budget trim** (`CONTEXT_BUDGET_PERCENT`, default 80%) â€” at API
   call time, ensures total tokens fit within the provider's context window

The token budget uses `tiktoken` for accurate token counting. The budget
formula is: `input_budget = (context_window Ã— 80%) âˆ’ max_output_tokens`.
Messages are included newest-to-oldest until the budget is exhausted, with
the system prompt always included.

With `MAX_HISTORY=10`, the token budget acts as a safety net for oversized
messages. Increase `MAX_HISTORY` (e.g., 50) to let the token budget be the
primary decision-maker for which messages go to the API.

### Token Usage Logging
Every API call logs actual token consumption (input + output) at INFO level,
extracted from each provider's response metadata â€” not estimates. Per-channel
cumulative totals are tracked in memory and logged at DEBUG. This provides a
cost baseline for comparing context management techniques.

Set `LOG_LEVEL=DEBUG` to see full token budget and usage details on every call.

---

## Commands

ðŸ”’ = Administrator permission required

### `!prompt` â€” System Prompt
| Usage | Description | Permission |
|-------|-------------|------------|
| `!prompt` | Show current system prompt | All users |
| `!prompt <text>` | Set new system prompt | ðŸ”’ Admin |
| `!prompt reset` | Reset to default prompt | ðŸ”’ Admin |

### `!ai` â€” AI Provider
| Usage | Description | Permission |
|-------|-------------|------------|
| `!ai` | Show current provider and available options | All users |
| `!ai <provider>` | Set provider: `openai`, `anthropic`, `deepseek` | ðŸ”’ Admin |
| `!ai reset` | Reset to default provider | ðŸ”’ Admin |

### `!autorespond` â€” Auto-Response
| Usage | Description | Permission |
|-------|-------------|------------|
| `!autorespond` | Show current status and options | All users |
| `!autorespond on` | Enable auto-response to all messages | ðŸ”’ Admin |
| `!autorespond off` | Disable auto-response | ðŸ”’ Admin |

### `!thinking` â€” DeepSeek Reasoning Display
| Usage | Description | Permission |
|-------|-------------|------------|
| `!thinking` | Show current status and options | All users |
| `!thinking on` | Display full reasoning in Discord + log at INFO | ðŸ”’ Admin |
| `!thinking off` | Answer only in Discord, reasoning logged at DEBUG | ðŸ”’ Admin |

**Notes:**
- Only applies to `deepseek-reasoner` model which returns `reasoning_content`
- Reasoning content is always logged (INFO when on, DEBUG when off)
- Reasoning never stored in conversation history or sent to API
- Displayed as a separate message before the answer, prefixed with
  `[DEEPSEEK_REASONING]:`

### `!history` â€” History Management
| Usage | Description | Permission |
|-------|-------------|------------|
| `!history` | Display recent history (last 25 messages) | ðŸ”’ Admin |
| `!history <count>` | Display N most recent messages | ðŸ”’ Admin |
| `!history clean` | Remove commands/artifacts from history | ðŸ”’ Admin |
| `!history reload` | Reload history from Discord | ðŸ”’ Admin |

### `!status` â€” Channel Overview
| Usage | Description | Permission |
|-------|-------------|------------|
| `!status` | Show all current channel settings | All users |

### Direct Provider Addressing
Address a specific provider without changing channel defaults:
```
openai, draw a picture of a sunset
anthropic, explain quantum physics
deepseek, solve this math problem
```

---

## Configuration

See [README_ENV.md](README_ENV.md) for comprehensive environment variable
documentation.

---

## Architecture

```
â”œâ”€â”€ main.py                    # Entry point
â”œâ”€â”€ bot.py                     # Core Discord events, message routing
â”œâ”€â”€ config.py                  # Environment variable configuration
â”œâ”€â”€ commands/                  # Modular command system (6 commands)
â”œâ”€â”€ ai_providers/              # Provider implementations + factory
â”‚   â”œâ”€â”€ openai_provider.py         # GPT models + image generation
â”‚   â”œâ”€â”€ anthropic_provider.py      # Claude models
â”‚   â””â”€â”€ openai_compatible_provider.py  # DeepSeek + any compatible API
â””â”€â”€ utils/
    â”œâ”€â”€ context_manager.py         # Token budget + usage accumulator
    â”œâ”€â”€ response_handler.py        # AI response processing + Discord delivery
    â”œâ”€â”€ provider_utils.py          # Provider override parsing
    â””â”€â”€ history/                   # History management subsystem
        â”œâ”€â”€ message_processing.py      # Noise filtering + API payload builder
        â”œâ”€â”€ cleanup_coordinator.py     # Post-load trim and cleanup
        â”œâ”€â”€ realtime_settings_parser.py # Settings recovery from Discord history
        â””â”€â”€ ...                        # Loading, storage, diagnostics
```

### Key Patterns
- **Provider singleton caching** â€” each provider instantiated once, reused
- **Async executor wrapping** â€” all synchronous API calls in thread pool
- **Three-layer noise filtering** â€” runtime, load-time, and API payload
- **Token-budget context building** â€” provider-aware, percentage-based
- **Token usage tracking** â€” actual API usage logged per-call and accumulated
- **Settings persistence** â€” parsed from Discord message history on startup
